{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_Final_HISPI_5_25_20.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be4f9c228cb0414da6e1dfd9e644d52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c3f3c6e6ed67428ca7665f196022ee76",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a1f3d8c90f4849369ac1b57eb593bb4a",
              "IPY_MODEL_7c1e2c42755a49fc92a9371d7b7b0750"
            ]
          }
        },
        "c3f3c6e6ed67428ca7665f196022ee76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1f3d8c90f4849369ac1b57eb593bb4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e1349373168c4fa9a54d4a7fc9010b53",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f727f346b48e4e6aa988a32364598adb"
          }
        },
        "7c1e2c42755a49fc92a9371d7b7b0750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a3a9cff2fcf54555a2574a302e891cdf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 393kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3b2877a451a4ee68bec9e6ae762de18"
          }
        },
        "e1349373168c4fa9a54d4a7fc9010b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f727f346b48e4e6aa988a32364598adb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3a9cff2fcf54555a2574a302e891cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3b2877a451a4ee68bec9e6ae762de18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elliehaber/icd_code_pred/blob/master/Copy_of_Final_HISPI_5_25_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4Nue0XaDNNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import io\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUX4pnkUuCRu",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnMFarmf0PKV",
        "colab_type": "code",
        "outputId": "4e7d9166-25f4-4b4f-ca9d-4d602cc37e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4c4KqOgDYIu",
        "colab_type": "code",
        "outputId": "5892dcd1-dac0-4dac-a5e2-62a2c8366b0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BTb-KRlDYN8",
        "colab_type": "code",
        "outputId": "e3171cfe-5e9e-4a44-fc01-4f04a3e3a4f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#patient notes data\n",
        "df_notes = pd.read_csv('NOTEEVENTS.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldqGAT4_DYRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#icd diagnoses data\n",
        "df_icd_diag = pd.read_csv('DIAGNOSES_ICD 2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTMZUMjJMtEE",
        "colab_type": "code",
        "outputId": "7eacc4c5-9aff-4d0c-fbef-2449fcf097ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "#Identify the top 10 occurring ICD-9 Codes\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_icd_diag.head()\n",
        "freq = df_icd_diag['ICD9_CODE'].value_counts()[:10].index.tolist()\n",
        "x = df_icd_diag['ICD9_CODE'].value_counts()[:50].index.tolist()\n",
        "\n",
        "\n",
        "print(sum(df_icd_diag['ICD9_CODE'].value_counts()[:10]))\n",
        "freq_val = df_icd_diag['ICD9_CODE'].value_counts()[:10]\n",
        "plt.bar(freq, freq_val)\n",
        "plt.title('Top Ten ICD-9 Codes')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlabel('ICD9-Codes')\n",
        "\n",
        "print(freq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "106379\n",
            "['4019', '4280', '42731', '41401', '5849', '25000', '2724', '51881', '5990', '53081']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dRLbyi1Phse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Filter for notes with discharge summary\n",
        "df_notes_discharge_summ = df_notes.loc[df_notes.CATEGORY == 'Discharge summary']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxNH5cx5W1Cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_notes_discharge_summ_last = (df_notes_discharge_summ.groupby(['SUBJECT_ID', 'HADM_ID']).nth(-1)).reset_index()\n",
        "assert df_notes_discharge_summ_last.duplicated(['HADM_ID']).sum() == 0, 'Multiple discharge summaries per admission'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voyXheqEQW2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_icd_notes = pd.merge(df_icd_diag[['SUBJECT_ID', 'HADM_ID', 'SEQ_NUM', 'ICD9_CODE']], \\\n",
        "df_notes_discharge_summ_last[['SUBJECT_ID', 'HADM_ID', 'TEXT']], on= ['SUBJECT_ID', 'HADM_ID'], how = 'left'\n",
        ")\n",
        "\n",
        "assert len(df_icd_diag) == len(df_icd_notes), 'Number of rows increased'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzHycoXwxexz",
        "colab_type": "code",
        "outputId": "a7587928-b15f-42fd-cd8b-3d9fb2bca8ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#filter for first admission\n",
        "df_icd_notes_1 = df_icd_notes[df_icd_notes.ICD9_CODE.isin(x)]\n",
        "print(len(df_icd_notes_1))\n",
        "df_icd_notes = df_icd_notes[df_icd_notes.ICD9_CODE.isin(freq)]\n",
        "df_icd_notes_1 = df_icd_notes[df_icd_notes.ICD9_CODE.isin(x)]\n",
        "\n",
        "t = df_icd_notes.drop_duplicates(subset='HADM_ID', keep=\"first\", inplace=True)\n",
        "df_icd_notes = df_icd_notes.dropna(how='any',subset=['TEXT'])\n",
        "\n",
        "len(df_icd_notes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "242728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40562"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ9wxKM1X3fa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extract Hospital Course section of notes\n",
        "\n",
        "df_icd_notes\n",
        "lst = []\n",
        "for i in df_icd_notes['TEXT']:\n",
        "  i = str(i).lower()\n",
        "  if 'concise summary of hospital course as follows:' in i:\n",
        "    start = i.find('concise summary of hospital course as follows:') \n",
        "    lst.append(i[start+46:])\n",
        "  elif 'hospital course:' in i:\n",
        "    start = i.find('hospital course:') \n",
        "    lst.append(i[start+16:])\n",
        "  else: \n",
        "    lst.append('not valid')\n",
        "\n",
        "df_icd_notes['Hosp_course'] = lst\n",
        "\n",
        "df_icd_notes = df_icd_notes[df_icd_notes.Hosp_course != 'not valid']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BHsClkxZVz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extract History of Present Illness section of notes\n",
        "\n",
        "df_icd_notes\n",
        "lst = []\n",
        "for i in df_icd_notes['TEXT']:\n",
        "  i = str(i).lower()\n",
        "  if 'history of present illness' in i:\n",
        "    start = i.find('history of present illness:')\n",
        "    lst.append(i[start+27:])\n",
        "  else:\n",
        "    lst.append('not valid')\n",
        "\n",
        "\n",
        "df_icd_notes['hist_pres_illness'] = lst\n",
        "\n",
        "df_icd_notes = df_icd_notes[df_icd_notes.hist_pres_illness != 'not valid']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1815J5eMa8rE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_icd_notes = df_icd_notes.dropna(how='any',subset=['Hosp_course'])\n",
        "df_icd_notes = df_icd_notes.dropna(how='any',subset=['hist_pres_illness'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckpDI5OXr7LM",
        "colab_type": "code",
        "outputId": "4e15fcde-079c-4c82-b505-c54110cc5c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBIQGO34_G3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.compat.v1.Session(config=config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo9ASYy-r8v1",
        "colab_type": "code",
        "outputId": "3dff8cec-518d-42bf-baa7-bf4f1f6f54a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert pytorch-nlp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hCollecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.5.0+cu101)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.13.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.13 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.16.13)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.17.0,>=1.16.13->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert, pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSz3at1Tr-ed",
        "colab_type": "code",
        "outputId": "f6086c75-8b13-4b71-f304-f502601058fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc1803IxsBGB",
        "colab_type": "code",
        "outputId": "02c8aea1-f6be-4abf-c9dd-91b905cb1da7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxVD_-ZAB025",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
        "session = tf.compat.v1.Session(config=config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbzy_oTszfhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer() \n",
        "import string\n",
        "\n",
        "\n",
        "def preprocess(text):  \n",
        "    punc_list = string.punctuation+'0123456789'\n",
        "    t = str.maketrans(dict.fromkeys(punc_list, \"\"))\n",
        "    text = text.lower().translate(t)\n",
        "    text = text.replace('\\n','')\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhfkd2SSHfHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# labels_dict = {}\n",
        "# num = 0\n",
        "# for i in freq:\n",
        "#   labels_dict[str(i)] = num\n",
        "#   num+= 1\n",
        "\n",
        "# print(labels_dict)\n",
        "class2idx = {\n",
        "    '4019': 0,\n",
        "    '4280': 1,\n",
        "    '42731': 2,\n",
        "    '41401': 3,\n",
        "    '5849': 4,\n",
        "    '25000': 5,\n",
        "    '2724': 6,\n",
        "    '51881': 7,\n",
        "    '5990': 8,\n",
        "    '53081': 9\n",
        "}\n",
        "\n",
        "# class2idx = {\n",
        "#     4019: 0,\n",
        "#     4280: 1,\n",
        "#     42731: 2,\n",
        "#     41401: 3,\n",
        "#     5849: 4,\n",
        "#     25000: 5,\n",
        "#     2724: 6,\n",
        "#     51881: 7,\n",
        "#     5990: 8,\n",
        "#     53081: 9\n",
        "# }\n",
        "\n",
        "idx2class = {v: k for k, v in class2idx.items()}\n",
        "\n",
        "\n",
        "df_icd_notes['ICD9_CODE'].replace(class2idx, inplace=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HliMK9lbUW5X",
        "colab_type": "code",
        "outputId": "cf186599-3dfa-4cae-b6b1-d059b2597aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df_icd_notes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>SEQ_NUM</th>\n",
              "      <th>ICD9_CODE</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>Hosp_course</th>\n",
              "      <th>hist_pres_illness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>112</td>\n",
              "      <td>174105</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Admission Date: [**2194-6-13**]        Dischar...</td>\n",
              "      <td>gi: the\\npatient was felt to likely have ano...</td>\n",
              "      <td>the patient is a [**age over 90 **]-year-old...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>113</td>\n",
              "      <td>109976</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9</td>\n",
              "      <td>Admission Date: [**2140-12-12**]        Discha...</td>\n",
              "      <td>the patient was admitted to the intensive\\nc...</td>\n",
              "      <td>the patient is a 35 year old\\ngentleman who ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>114</td>\n",
              "      <td>178393</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Admission Date:  [**2146-8-29**]       Dischar...</td>\n",
              "      <td>the patient was admitted to the [**hospital1...</td>\n",
              "      <td>this is a 48-year-old man in\\ngenerally good...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>115</td>\n",
              "      <td>114585</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8</td>\n",
              "      <td>Admission Date:  [**2194-10-16**]             ...</td>\n",
              "      <td>\\nshe was taken to the or by dr. [**first name...</td>\n",
              "      <td>\\nthe patient is a 75 y/o female who presents ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>117</td>\n",
              "      <td>140784</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Admission Date:  [**2133-4-7**]     Discharge ...</td>\n",
              "      <td>\\n1.  hypotension.  the patient was admitted t...</td>\n",
              "      <td>the patient is a 49 year old\\nwoman with a h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650962</th>\n",
              "      <td>97164</td>\n",
              "      <td>109302</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7</td>\n",
              "      <td>Admission Date:  [**2134-11-26**]             ...</td>\n",
              "      <td>\\nassessment and plan: ms. [**known lastname 2...</td>\n",
              "      <td>\\nms. [**known lastname 2564**] is an 83 y/o f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650986</th>\n",
              "      <td>97484</td>\n",
              "      <td>172304</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Admission Date:  [**2196-8-19**]              ...</td>\n",
              "      <td>\\nthe patient tolerated her procedure well, an...</td>\n",
              "      <td>\\n79 f with no past oncologic history who pres...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650993</th>\n",
              "      <td>97488</td>\n",
              "      <td>152542</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2</td>\n",
              "      <td>Admission Date:  [**2128-4-8**]              D...</td>\n",
              "      <td>\\nmr. [**known lastname 17811**] was admitted ...</td>\n",
              "      <td>\\n66m transferred from [**hospital1 18**] [**l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>651007</th>\n",
              "      <td>97488</td>\n",
              "      <td>161999</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8</td>\n",
              "      <td>Admission Date:  [**2128-8-27**]              ...</td>\n",
              "      <td>\\n*)neuro: patient was admitted [**2128-8-27**...</td>\n",
              "      <td>\\nthe patient is a 67 year old right handed ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>651038</th>\n",
              "      <td>97497</td>\n",
              "      <td>168949</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2</td>\n",
              "      <td>Admission Date:  [**2106-7-16**]              ...</td>\n",
              "      <td>\\n# paroxysmal atrial fibrillation:  patient h...</td>\n",
              "      <td>\\ndr [**known lastname 8993**] is a 57 yo man ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34844 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        SUBJECT_ID  ...                                  hist_pres_illness\n",
              "31             112  ...    the patient is a [**age over 90 **]-year-old...\n",
              "35             113  ...    the patient is a 35 year old\\ngentleman who ...\n",
              "36             114  ...    this is a 48-year-old man in\\ngenerally good...\n",
              "50             115  ...  \\nthe patient is a 75 y/o female who presents ...\n",
              "67             117  ...    the patient is a 49 year old\\nwoman with a h...\n",
              "...            ...  ...                                                ...\n",
              "650962       97164  ...  \\nms. [**known lastname 2564**] is an 83 y/o f...\n",
              "650986       97484  ...  \\n79 f with no past oncologic history who pres...\n",
              "650993       97488  ...  \\n66m transferred from [**hospital1 18**] [**l...\n",
              "651007       97488  ...  \\nthe patient is a 67 year old right handed ma...\n",
              "651038       97497  ...  \\ndr [**known lastname 8993**] is a 57 yo man ...\n",
              "\n",
              "[34844 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSXgiSYSV-Gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = df_icd_notes.ICD9_CODE.values\n",
        "labels = labels.astype(np.long)\n",
        "\n",
        "sentences_hosp = df_icd_notes.hist_pres_illness.values\n",
        "sentences_hosp = sentences_hosp.astype('str')\n",
        "\n",
        "test_labels = labels[27001:30202]\n",
        "test_sent = sentences_hosp[27001:30202]\n",
        "\n",
        "for i in range(len(test_sent)):\n",
        "    sent = test_sent[i]\n",
        "    sent = preprocess(sent)\n",
        "    test_sent[i] = sent\n",
        "    \n",
        "# sentences_hist = df_icd_notes.hist_pres_illness.values\n",
        "# sentences_hist = sentences_hist.astype(np.string_)\n",
        "# sentences = df_icd_notes.TEXT.values\n",
        "# sentences = sentences.astype(np.string_)\n",
        "\n",
        "\n",
        "labels = labels[:27000]\n",
        "sentences_hosp = sentences_hosp[:27000]\n",
        "\n",
        "for i in range(len(sentences_hosp)):\n",
        "    sent = sentences_hosp[i]\n",
        "    sent = preprocess(sent)\n",
        "    sentences_hosp[i] = sent\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wUnp-5Og7fR",
        "colab_type": "code",
        "outputId": "58e4bec9-ae4b-47df-c440-8ad4ef2e7dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/b5/ac41e3e95205ebf53439e4dd087c58e9fd371fd8e3724f2b9b4cdb8282e5/transformers-2.10.0-py3-none-any.whl (660kB)\n",
            "\r\u001b[K     |▌                               | 10kB 32.8MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 3.3MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████                            | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 92kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 665kB 2.8MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 25kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 61.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 59.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=be1bae501888374b127bbd37ab98a7336eed7af4a2ea6a22c684b3fad24689ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhtBm6tzsNfV",
        "colab_type": "code",
        "outputId": "8f365ea2-dae6-4060-df61-dd172ef27038",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "be4f9c228cb0414da6e1dfd9e644d52c",
            "c3f3c6e6ed67428ca7665f196022ee76",
            "a1f3d8c90f4849369ac1b57eb593bb4a",
            "7c1e2c42755a49fc92a9371d7b7b0750",
            "e1349373168c4fa9a54d4a7fc9010b53",
            "f727f346b48e4e6aa988a32364598adb",
            "a3a9cff2fcf54555a2574a302e891cdf",
            "b3b2877a451a4ee68bec9e6ae762de18"
          ]
        }
      },
      "source": [
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "import logging\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences_hosp:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "print('Original: ', sentences_hosp[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 315837.40B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be4f9c228cb0414da6e1dfd9e644d52c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Original:   \n",
            "Token IDs: tensor([  101,  1996,  5776,  2003,  1037,  2287,  2058,  2095, 11614,  2158,\n",
            "        24415,  1037,  2381,  1997, 27233,  4588, 17359, 17119,  4295, 21887,\n",
            "         2854, 16749, 10521, 19500,  3570,  2695,  2026, 24755, 25070,  1999,\n",
            "        14971,  7542,  1999,  2004,  2092,  2004, 15850, 16185, 14778,  2483,\n",
            "         2040,  3591,  2007, 11463, 26474,  1998,  8376,  2102,  3255,  1996,\n",
            "         5776,  2988, 11463,  6761,  4588, 14708,  2015,  2335,  2144,  7610,\n",
            "         2006,  1996,  2154,  3188,  2000,  9634,  2053, 19610,  3686,  7834,\n",
            "         2483,  2030, 28433,  3406,  5403, 12871, 14708,  2015,  2020,  6065,\n",
            "         1996,  5776,  2018,  1037,  2381,  1997, 10199,  8189,  1999,  1996,\n",
            "         5776,  2036,  2988,  2108,  7138,  4974,  2098, 16342,  2094,  2007,\n",
            "         2019,  3623,  1999,  2010, 10381,  2275, 10521,  9006, 13028,  2005,\n",
            "         2029,  2002,  2001,  2635,  4942,  2989,  8787,  9152, 13181, 25643,\n",
            "        17119,  2378, 24415,  4335,  2006,  1996,  2572,  1997,  8312,  1996,\n",
            "         8030,  7347, 27870,  2094,  1996,  5776,  3967, 18442,  9152,  2010,\n",
            "         7473,  2361,  2040,  2741,  2032,  2000,  2059, 14074,  9152,  1999,\n",
            "         1996,  3968,  1996,  1052,  2001,  2179,  2000,  2031,  1037, 19610,\n",
            "        10610, 26775,  4183,  1997, 10548,  2013,  1037, 26163,  1997,  2000,\n",
            "         2002,  2001,  2445,  4921, 21572,  2669,  7646,  4921, 20989,  1998,\n",
            "         9099, 25608,  2098,  1996,  2034,  1997,  3197,  1997, 23947,  2098,\n",
            "         2417,  2668,  4442,  3806, 13181, 29110,  6779,  2001, 17535,  1996,\n",
            "        24343,  3322,  2018,  2019, 23969,  2290,  2007,  7263, 14092,  3431,\n",
            "        19927,  1996,  5776,  2001,  3255,  2489,  1996,  5776,  2059,  2018,\n",
            "         2019, 13699, 19565,  3207,  1997,  4942,  6238, 12032,  3108,  3255,\n",
            "         1999,  1996,  3968,  2007,  2000,  2395,  4769,  3431,  1999,  1058,\n",
            "         2000, 21210, 14083,  2966,  2381,  3278,  2005,  3356,  3806, 13181,\n",
            "        18447, 19126,  3468,  2098,  1999,  2019,  9686,  7361,  3270,  3995,\n",
            "        12617, 13181,  8566, 10244, 15460,  3597,  7685,  3662,  2019,  5313,\n",
            "        17119,  1999,  1996,  1052,  8516, 21694,  1998, 11888,  3806, 18886,\n",
            "         7315, 21887,  2854, 16749, 10521, 19500,  3570,  2695,  2026, 24755,\n",
            "        25070,  1999, 14971,  7542,  1999,  1998, 28378,  4013, 16677, 23760,\n",
            "        13181, 21281,  2381,  1997, 15850, 16185, 14778,  2483,  5051,  8737,\n",
            "         4048,  3995,  3593,  2381,  1997,  2019, 17577,  2381,  1997,  2235,\n",
            "         6812,  2884,  6767,  2140, 19722,  7393,  3570,  2695, 10439, 10497,\n",
            "        22471, 20936,  2229,  3570,  2695, 13749, 20023,  2389,  5886,  6200,\n",
            "         7192,  1060,  2381,  1997, 16844,  2594, 26572,  4523,  1998,  9033,\n",
            "        21693,  9314,  4305, 16874,  2594, 18845,  6190, 24164, 10623,  3111,\n",
            "         1996,  5776,  2038,  2053,  2124,  4319,  2035,  2121, 17252,  7583,\n",
            "        21261,  2015,  1996,  5776,  2001,  2006,  8292,  2571, 13578,  2595,\n",
            "         2004,  8197,  6657,  3653,  2094,  8977,  5643,  8823,  3630,  4135,\n",
            "         2140, 10047, 24979,  9152, 13181, 25643, 17119,  2378, 10975,  3619,\n",
            "        10085,  4818,  2381,  2002,  2003,  1037,  3394,  7522,  2171,  3988,\n",
            "         2171,  2483,  6556,  9098,  2381,  2591,  6544,  2224,  2029,  2003,\n",
            "         2378, 19699,  2063, 15417,  2496,  2007,  2365,  7011,  4328,  2135,\n",
            "         2381,  2512,  8663, 18886,  8569,  7062, 23302,  7749,  2006,  9634,\n",
            "         2004,  4076,  8995,  5751, 28403,  2140,  5751,  1997,  4860,  2668,\n",
            "         3778,  8187, 16464,  3446,  1997,  1998,  7722,  2006, 23675, 28745,\n",
            "        24454,  2389,  1996,  5776,  2596,  6625, 21030,  3372,  7749,  2001,\n",
            "         4895, 28578, 17007,  3085,  3272,  2005,  5122,  8663, 19792,  6593,\n",
            "        11444,  4318, 14163, 13186,  7911, 12821, 14049,  2951,  3278,  2005,\n",
            "         1996, 19610, 10610, 26775,  4183,  1997,  4632, 16238,  2682,  1037,\n",
            "        18044,  1997,  1037, 21122,  3988, 23616,  2001,  2007,  2019, 16914,\n",
            "         1997,   102])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZZ7snW1sjlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Create attention masks\n",
        "# attention_masks = []\n",
        "\n",
        "# # Create a mask of 1s for each token followed by 0s for padding\n",
        "# for seq in input_ids:\n",
        "#   seq_mask = [float(i>0) for i in seq]\n",
        "#   attention_masks.append(seq_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvPU2bSksl0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                          random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpBA-WYCGKHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDbXK0wNsnxu",
        "colab_type": "code",
        "outputId": "608f7255-57d2-4a21-e66f-73e1df20ea03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6P1aXgWu31R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev8NzRI2soy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 12\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yGDx7Geu7Fi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5Uorf5wssZH",
        "colab_type": "code",
        "outputId": "14405b9e-b61b-41cf-9484-50613b771ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=10)\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:32<00:00, 12586652.29B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCiy2mdTswB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01}\n",
        "]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXFQ_Tx1s1FM",
        "colab_type": "code",
        "outputId": "324c7331-86a6-4ca5-81ef-a80c5174d5e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=1e-5,\n",
        "                     warmup=.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYDJxUGgtRRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "from sklearn.metrics import f1_score\n",
        "errors = {\"0\": 0, \"1\":0, \"2\":0, \"3\":0, \"4\":0, \"5\":0, \"6\":0, \"7\":0, \"8\":0, \"9\":0}\n",
        "total = {\"0\": 0, \"1\":0, \"2\":0, \"3\":0, \"4\":0, \"5\":0, \"6\":0, \"7\":0, \"8\":0, \"9\":0}\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    ##determine frequent errors\n",
        "    for i in range(len(pred_flat)):\n",
        "      if labels_flat[i] != pred_flat[i]:\n",
        "        errors[str(labels_flat[i])] += 1\n",
        "      total[str(labels_flat[i])] += 1\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuuouGbXuoUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "\n",
        "def aucscore(labels, preds):\n",
        "  # print(preds)\n",
        "  pred_flat = np.max(preds, axis=1).flatten()\n",
        "  print(pred_flat)\n",
        "  labels_flat = labels\n",
        "  print('x')\n",
        "  micro = roc_auc_score(labels_flat, pred_flat, average='micro', multi_class='ovo')\n",
        "  print('x')\n",
        "  macro = roc_auc_score(labels_flat, pred_flat, average='macro', multi_class='ovo')\n",
        "  weighted = roc_auc_score(labels_flat, pred_flat, average='weighted', multi_class='ovo')\n",
        "\n",
        "  return micro, macro, weighted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_kDBAuHroxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1score(labels, preds):\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "\n",
        "  micro = f1_score(labels_flat, pred_flat, average='micro')\n",
        "  macro = f1_score(labels_flat, pred_flat, average='macro')\n",
        "  weighted = f1_score(labels_flat, pred_flat, average='weighted')\n",
        "\n",
        "  return micro, macro, weighted\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPzkn4TqXT4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BH8cymnDtdT",
        "colab_type": "code",
        "outputId": "41bd8d22-be0d-4f61-f4e8-68527e4b4247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  total_eval_loss=0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "\n",
        "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  f1_micr, f1_macr, f1_weight = 0,0,0\n",
        "  auc_micr, auc_macr, auc_weight = 0,0,0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        " \n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    total_eval_loss+= loss.item()\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    tmp_f1_micr, tmp_f1_macr, tmp_f1_weight = f1score(label_ids, logits)\n",
        "    #tmp_auc_micr, tmp_auc_macr, tmp_auc_weight = aucscore(label_ids, logits)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    #calculate f1 scores\n",
        "    f1_micr += tmp_f1_micr\n",
        "    f1_macr += tmp_f1_macr\n",
        "    f1_weight += tmp_f1_weight\n",
        "\n",
        "    # #calculate auc\n",
        "    # auc_micr += tmp_auc_micr\n",
        "    # auc_macr += tmp_auc_macr\n",
        "    # auc_weight += tmp_auc_weight\n",
        "\n",
        "    nb_eval_steps += 1\n",
        "  print('TOTAL EVAL LOSS: ', total_eval_loss/len(validation_dataloader))\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "  print('F1 micro:', f1_micr/nb_eval_steps)  \n",
        "  print('F1 macro:', f1_macr/nb_eval_steps)\n",
        "  print('F1 weight:', f1_weight/nb_eval_steps)\n",
        "  print('    DONE.')\n",
        "  #print('AUC macro: ', auc_macr/nb_eval_steps )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/4 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 1.9881248489426977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  25%|██▌       | 1/4 [27:27<1:22:22, 1647.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TOTAL EVAL LOSS:  1.8977231979370117\n",
            "Validation Accuracy: 0.3437037037037038\n",
            "F1 micro: 0.3437037037037038\n",
            "F1 macro: 0.22127482681927124\n",
            "F1 weight: 0.28686397758619986\n",
            "    DONE.\n",
            "Train loss: 1.7385604045420517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 2/4 [54:56<54:56, 1648.01s/it]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TOTAL EVAL LOSS:  1.8550971746444702\n",
            "Validation Accuracy: 0.4355555555555552\n",
            "F1 micro: 0.4355555555555552\n",
            "F1 macro: 0.31880858433160014\n",
            "F1 weight: 0.40557335257335264\n",
            "    DONE.\n",
            "Train loss: 1.6221277959552811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  75%|███████▌  | 3/4 [1:22:25<27:28, 1648.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TOTAL EVAL LOSS:  2.0220038890838623\n",
            "Validation Accuracy: 0.46074074074074056\n",
            "F1 micro: 0.46074074074074056\n",
            "F1 macro: 0.3401730641492544\n",
            "F1 weight: 0.42704385737719064\n",
            "    DONE.\n",
            "Train loss: 1.5408328406604719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 4/4 [1:49:53<00:00, 1648.42s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TOTAL EVAL LOSS:  1.667733073234558\n",
            "Validation Accuracy: 0.46148148148148155\n",
            "F1 micro: 0.46148148148148155\n",
            "F1 macro: 0.34392354039258805\n",
            "F1 weight: 0.4268039121372456\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVqGcGXWAxSJ",
        "colab_type": "code",
        "outputId": "8b366797-87ef-4720-9269-939a4fb1bfcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "errors"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 480,\n",
              " '1': 948,\n",
              " '2': 741,\n",
              " '3': 270,\n",
              " '4': 959,\n",
              " '5': 432,\n",
              " '6': 224,\n",
              " '7': 834,\n",
              " '8': 986,\n",
              " '9': 332}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWtI4qJyA0FW",
        "colab_type": "code",
        "outputId": "a5cc80da-3871-492b-ad3c-89a2fd33d204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "total"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 1432,\n",
              " '1': 1508,\n",
              " '2': 1116,\n",
              " '3': 1716,\n",
              " '4': 1464,\n",
              " '5': 432,\n",
              " '6': 224,\n",
              " '7': 1588,\n",
              " '8': 988,\n",
              " '9': 332}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLYMw4xHFOzU",
        "colab_type": "code",
        "outputId": "0bb7780d-fbb9-4a0d-8dc6-8b222a413bed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import os\n",
        "from transformers import WEIGHTS_NAME, CONFIG_NAME\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "# If we save using the predefined names, we can load using `from_pretrained`\n",
        "output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
        "output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
        "\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "model_to_save.config.to_json_file(output_config_file)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "# model_to_save.save_pretrained(output_dir)\n",
        "# tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBfTI_RcID2d",
        "colab_type": "code",
        "outputId": "da7e716c-54b5-4408-d148-2b52de31e394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_sent:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(test_labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', test_sent[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  this  year old man preop aortic valve replacement forstenosis and coronary bypass for double vessel disease wasadmitted after a syncopal episode at home  at an outsidehospital he was found to have heme positive stools and ahematocrit of  most recent echo showed significant aorticstenosis with peak and mean gradients of  and  and estimatedvalve area of cm sq subsequentlyly he  underwent cardiaccath which revealed multiple vessel diseasepast medical historyaortic stenosiscoronary artery diseasehypertensiondyslipidemiacongestive heart failurepolymyalgia rheumaticaquestion of rheumatoid arthritissp right inguinal hernia repairsp lens implants for cataractssocial historypatient is a retired automobile mechanic he is independent forall adls lives with his wife who has alzheimers and his sontobacco history deniesetoh socially but has had no alcohol recentlyillicit drugs deniesfamily historyno family history of early mi arrhythmia cardiomyopathies orsudden cardiac death otherwise noncontributoryphysical examadmissionpulse  o sat bp  right    left height    weight lbsgeneral welldeveloped wellnourished male in no acutedistressskin dry x intact xheent perrla x eomi xneck  supple x full rom xchest lungs clear bilaterally xheart rrr x  irregular   murmur  highpitched systolicmurmurabdomen soft x nondistended x nontender x  bowel sounds xextremities warm x wellperfused x  edema nonevaricosities bilateral superficial leftrightneuro grossly intact alert and oriented x pulsesfemoral      right   left dp           right   left pt           name ni    left radial       right   left carotid bruit        rightleft transmitted cardiac murmurpertinent results ecg sinus rhythm left ventricular hypertrophylateral t wave changes probably due to left ventricularhypertrophy no previous tracing available for comparison ct chest without contrast  calcified aortic valvemildly calcified aortic arch  densely calcified coronaryarteries  cholelithiasis  mildly calcified takeoffs of theleft common carotid and left subclavian arteries carotid us right ica stenosis  left ica stenosis echo prebypass the left atrium is dilated nospontaneous echo contrast or thrombus is seen in the body of theleft atriumleft atrial appendage or the body of the rightatriumright atrial appendage no atrial septal defect is seenby d or color doppler there is moderate symmetric leftventricular hypertrophy the left ventricular cavity size isnormal there is mild regional left ventricular systolicdysfunction with focalities in the circumflex distributionoverall left ventricular systolic function is mildly depressedlvef   doppler parameters are most consistent with gradei mild left ventricular diastolic dysfunction rightventricular chamber size and free wall motion are normal thereare simple atheroma in the aortic arch the aortic valveleaflets are severely thickeneddeformed there is criticalaortic valve stenosis valve area cm mild  aorticregurgitation is seen the mitral valve leaflets are mildlythickened there is no mitral valve prolapse mild  mitralregurgitation is seen there is a small pericardial effusionpostbypass patient is on epinephrine mcgkgmin normal rvsystolic function overall lvef  the bioprosthetic valve inthe native aortic position is stable and functioning well withresidual mean gradient of mm of hg the thoracic aorta isintact mild mr pm blood wbc rbc hgb hctmcv mch mchc rdw plt ct pm blood wbc rbc hgbhct mcv mch mchc rdw plt ct am blood wbc rbc hgb hctmcv mch mchc rdw plt ct pm blood pt ptt inrpt pm blood pt ptt inrpt pm blood glucose urean creat nak cl hco angap am blood glucose urean creat nak cl hco angap am blood glucose urean creat nak cl hco angap pm blood alt ast ldldh alkphostotbili am blood calcium phos mgbrief hospital courseas mentioned in the hpi mr known lastname  was transferred from outsidefollowing a syncopal episode at home cardiology servicemedically managed patient upon admission and he wasappropriately workedup for cardiac surgery this includedcarotid us chest ct echo gi consult dental consult alongwith usual preop lab work this was achieved over several daysand on  he was brought to the operating room where heunderwent an aortic valve replacement and coronary artery bypassgraft x  please see operative report for surgical detailsfollowing surgery he was transferred to the cvicu for invasivemonitoring in stable conditionon postoperative day one he was weaned from sedation awokeneurologically intact and extubated on postop day two hischest tubes were removed and he was transferred to the telemetryfloor for further care on postop day three his epicardialpacing wires were removeddiuresis towards his preoperative weight and pysical therapyworked with him for mobility  he continued to make progresswhile working with physical therapy for strength and mobilityon postop day five he was discharged to home with vna serviceswith the appropriate medications and followup appointmentsdischarge restrictions activity and medications were discussedprior to leaving the hospitalmedications on admissionlisinopril mg po daily lasix mg po daily aspirin mg podaily simvastatin mg po daily calcium d mg po dailyprednisone mg po daily hydroxychloroquine mg po biddischarge medications aspirin  mg tablet delayed release ec sig one tablet delayed release ec po daily dailydisp tablet delayed release ecs refills docusate sodium  mg capsule sig one  capsule po bid times a daydisp capsules refills simvastatin  mg tablet sig two  tablet po dailydailydisp tablets refills lisinopril  mg tablet sig one  tablet po daily dailydisp tablets refills metoprolol tartrate  mg tablet sig  tablets po bid times a daydisp tablets refills prednisone  mg tablet sig three  tablet po dailydailydisp tablets refills oxycodoneacetaminophen  mg tablet sig  tablets poqh every  hours as needed for paindisp tablets refills hydroxychloroquine  mg tablet sig one  tablet po bid times a daydisp tablets refills pantoprazole  mg tablet delayed release ec sig one tablet delayed release ec po qh every  hoursdisp tablet delayed release ecs refills acetaminophen  mg tablet sig two  tablet po qhevery  hours as needed for paindischarge dispositionhome with servicefacilityhospital  vnadischarge diagnosisaortic stenosis sp aortic valve replacementcoronary artery disease sp coronary artery bypass graft x past medical historycongestive heart failurehypertensionhypercholesterolemiapolymalgia rheumaticarheumatoid arthritissp right inguinal hernia repairsp lens implants for cataractsdischarge conditiongooddischarge instructionsshower daily no baths or swimmingno lotions creams or powders to incisionsno driving for  weeks and off all narcoticsno lifting more than  pounds for  weeksreport any redness of or drainage from incisionsreport any fever greater than report any weight gain greater than  pounds a day or  pounds aweektake all medications as directedfollowup instructionsdr last name stitle  in  weeks telephonefax  dr first name namepattern  last name namepattern  in  weeksdr first name namepattern  last name namepattern  in  weeks telephonefax  hospital ward name   wound clinic in  weeksplease call for appointmentscompleted by\n",
            "Token IDs: tensor([  101,  2023,  2095,  2214,  2158,  3653,  7361, 20118, 28228,  2278,\n",
            "        10764,  6110,  2005, 16173, 12650,  1998, 21887,  2854, 11826,  2005,\n",
            "         3313,  6258,  4295,  2001,  4215, 22930,  3064,  2044,  1037, 26351,\n",
            "        29477,  2140,  2792,  2012,  2188,  2012,  2019,  2648, 15006, 23270,\n",
            "         2389,  2002,  2001,  2179,  2000,  2031, 19610,  2063,  3893, 14708,\n",
            "         2015,  1998,  6289, 14545,  3406, 26775,  4183,  1997,  2087,  3522,\n",
            "         9052,  3662,  3278, 20118, 28228,  6169,  6528, 12650,  2007,  4672,\n",
            "         1998,  2812, 17978,  2015,  1997,  1998,  1998,  4358, 10175,  3726,\n",
            "         2181,  1997,  4642,  5490,  3525,  2135,  2002,  9601, 15050, 11266,\n",
            "         2232,  2029,  3936,  3674,  6258,  4295, 19707,  2102,  2966,  2381,\n",
            "         7113, 28228,  2278, 26261, 27109, 27108,  7856,  2854, 16749,  4295,\n",
            "        10536,  4842, 29048,  5149, 14540, 11514,  5178, 10092,  8663,  8449,\n",
            "         6024,  2540,  4945, 18155, 24335, 21095, 10440,  1054,  5369, 25360,\n",
            "        20784, 15808,  3508,  1997,  1054,  5369, 12248,  3406,  3593, 27641,\n",
            "        13102,  2157, 13749, 20023,  2389,  2014,  6200, 10315,  2361, 10014,\n",
            "        27159,  2015,  2005,  4937,  5400, 16649,  6499, 13247,  2381, 24343,\n",
            "         2003,  1037,  3394,  9935, 15893,  2002,  2003,  2981,  2005,  8095,\n",
            "         4748,  4877,  3268,  2007,  2010,  2564,  2040,  2038, 21901,  2015,\n",
            "         1998,  2010,  2365,  3406,  3676, 21408,  2381, 23439, 18903,  2232,\n",
            "        14286,  2021,  2038,  2018,  2053,  6544,  3728,  8591, 28775,  2102,\n",
            "         5850, 23439,  7011,  4328,  2135,  2381,  3630,  2155,  2381,  1997,\n",
            "         2220,  2771, 12098, 25032, 22123, 26837,  2050,  4003, 18994,  7677,\n",
            "        15069,  3111,  2030,  6342, 17101, 15050,  2331,  4728,  2512,  8663,\n",
            "        18886,  8569,  7062, 23302, 11360,  4215, 25481, 14289,  4877,  2063,\n",
            "         1051,  2938, 17531,  2157,  2187,  4578,  3635, 20702,  6914, 21673,\n",
            "         2092, 24844, 18349,  5669,  2092,  3630,  9496, 14740,  3287,  1999,\n",
            "         2053, 11325, 10521, 19168,  4757,  4939,  4318,  1060, 10109,  1060,\n",
            "        21030,  3372,  2566, 12190,  2050,  1060,  1041, 20936,  1060, 18278,\n",
            "        10514,  9397,  2571,  1060,  2440, 17083,  1060,  8376,  2102,  8948,\n",
            "         3154, 17758,  2135,  1060, 22375, 25269,  2099,  1060, 12052, 20227,\n",
            "         2152, 23270,  7690, 25353, 16033, 10415, 20136, 16069,  2497, 26173,\n",
            "         2078,  3730,  1060,  2512, 10521,  6528,  5732,  1060,  2512,  6528,\n",
            "         4063,  1060,  6812,  2884,  4165,  1060, 10288,  7913, 22930,  3111,\n",
            "         4010,  1060,  2092,  4842, 25608,  2098,  1060,  3968, 14545,  3904,\n",
            "        10755, 11261, 24279, 17758, 23105,  2187, 15950,  2638, 10976,  7977,\n",
            "         2135, 10109,  9499,  1998,  8048,  1060, 23894,  7959, 22049,  2157,\n",
            "         2187,  1040,  2361,  2157,  2187, 13866,  2171,  9152,  2187, 15255,\n",
            "         2157,  2187,  2482,  4140,  3593,  7987, 14663,  2157,  2571,  6199,\n",
            "        11860, 15050, 20227,  4842, 10196,  3372,  3463, 14925,  2290,  8254,\n",
            "         2271,  6348,  2187, 18834,  7277,  7934, 23760, 13181, 21281, 28277,\n",
            "         1056,  4400,  3431,  2763,  2349,  2000,  2187, 18834,  7277,  7934,\n",
            "        10536,  4842, 13181, 21281,  2053,  3025, 16907,  2800,  2005,  7831,\n",
            "        14931,  3108,  2302,  5688, 10250,  6895, 10451, 20118, 28228,  2278,\n",
            "        10764,  4328,  6392,  2135, 10250,  6895, 10451, 20118, 28228,  2278,\n",
            "         7905, 19441, 10250,  6895, 10451, 21887, 20444, 19418,  3111, 16480,\n",
            "         2571, 15909, 12995,  6190, 19499, 10250,  6895, 10451, 19744,  2015,\n",
            "         1997,  1996,  2571,  6199,  2691,  2482,  4140,  3593,  1998,  2187,\n",
            "         4942, 20464, 21654, 28915,  2482,  4140,  3593,  2149,  2157, 24582,\n",
            "         2050, 26261, 27109,  2187, 24582,  2050, 26261, 27109,  9052,  3653,\n",
            "         3762, 15194,  1996,  2187, 26204,  2003, 29454,  4383, 16839, 26029,\n",
            "         5794, 14769,  9052,  5688,  2030, 16215, 21716,  8286,  2003,  2464,\n",
            "         1999,   102])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNP0E_W4IFoY",
        "colab_type": "code",
        "outputId": "3c91f253-c3ca-44c3-d5a4-16cbc58e9913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "test_inputs, _, test_labels, _ = train_test_split(input_ids, labels, \n",
        "                                                          random_state=2018, test_size=0.1)\n",
        "test_masks, _, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)\n",
        "\n",
        "test_inputs = torch.tensor(test_inputs)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B38x_IETIHQo",
        "colab_type": "code",
        "outputId": "4f35a339-571b-426d-9d82-8e2b537713b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "#initialize vars\n",
        "f1_micr_test = 0\n",
        "f1_macr_test = 0\n",
        "f1_weight_test = 0\n",
        "nb_eval_steps_test = 0\n",
        "\n",
        "# Predict \n",
        "for batch in test_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  # predictions.append(logits)\n",
        "  # true_labels.append(label_ids)\n",
        "\n",
        "  tmp_f1_micr, tmp_f1_macr, tmp_f1_weight = f1score(label_ids, logits)\n",
        "\n",
        "  #calculate f1 scores\n",
        "  f1_micr_test += tmp_f1_micr\n",
        "  f1_macr_test += tmp_f1_macr\n",
        "  f1_weight_test += tmp_f1_weight\n",
        "  nb_eval_steps_test += 1\n",
        "\n",
        "print('F1 micro test: ', f1_micr_test/nb_eval_steps_test)\n",
        "print('F1 macro test: ', f1_macr_test/nb_eval_steps_test)\n",
        "print('F1 weight test: ', f1_weight_test/nb_eval_steps_test)\n",
        "print('    DONE.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 3,201 test sentences...\n",
            "F1 micro test:  0.4173611111111111\n",
            "F1 macro test:  0.2986535493827161\n",
            "F1 weight test:  0.3927954144620808\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_ikHv5NKoCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
